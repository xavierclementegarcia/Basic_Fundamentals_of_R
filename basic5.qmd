---
title: "Introducción al análisis de datos con R"
subtitle: "Una introducción al lenguaje de programación"
author: "Xavier Clemente García"
format: 
  revealjs:
    theme: default
    footer: '<a href="https://xavierclementegarcia.github.io/Basic_Fundamentals_of_R/" target="_blank">Fundaments Basic R</a>'
echo: false
---

## Objetivo {.smaller}
Aprender como describir datos, formular hipótesis, validar supuestos y aplicar pruebas estadísticas en R. 

## Estadística descriptiva {.smaller}

**Medidas de tendencia central**
Existen varias pruebas que nos permiten describir la composición y comportamiento de nuestros datos. 
<br>
Vamos a clasificar medidas de tendencia central y medidas de dispersión 
```{r}
nombres<-c("Media", "Mediana")
significados_mtc<-c("Se refiere al promedio de un conjunto de datos","El valor que se encuentra en la mitad de un conjunto de daots")
mtc<-data.frame(nombres, significados_mtc)
colnames(mtc)<-c("Estadísticos", "Definición")
library(knitr)
mtc_kable<- kable(mtc)
mtc_kable
```

**Medidas de dispersión**

```{r}
dispersionames<-c("Desviación estándar", "Varianza", "Rango")
significados_md<-c("Qué tan dispersos están los datos en un conjunto","Dispersión de los datos entorno a la media", "Diferencias entre valores máximos y mínimos en una muestra de datos")
md<-data.frame(dispersionames, significados_md)
colnames(md)<-c("Estadísticos", "Definición")
library(knitr)
md_kable<- kable(md)
md_kable
```

# Ahora trabajaremos con dos bases de datos *PlantGrowth* y *Palmerpenguis* {.smaller}

## Primeros pasos con PlantGrowth {.smaller}

**Medidas de tendencia central**
```{r}
#| echo: true
data("PlantGrowth")
mean(PlantGrowth$weight)
median(PlantGrowth$weight)
```
**Medidas de dispersión**
```{r}
#| echo: true
sd(PlantGrowth$weight)
var(PlantGrowth$weight)
range(PlantGrowth$weight)
```
**Otra función**
```{r}
#| echo: true
summary(PlantGrowth$weight)
```
## Distribución de los datos {.smaller}
Antes de partir en un análisis de normalidad puede ser interesante oberservar como se distribuyen los datos. 
<br>
Para entender esto, habrá que partir desde un ejemplo básico.
<br>
```{r}
#| echo: false
hist(PlantGrowth$weight, xlab = "Peso de las plantas en tratamiento", ylab = "Frecuencias", main = "Un pequeño ejemplo de distribución")
```
**¿Cómo se entienden los datos?**

## Análisis de datos {.smaller}
Supongamos que partimos con el siguiente ejemplo. 
```{r}
#| echo: true
data("PlantGrowth")
attach(PlantGrowth)
planta<-data.frame(PlantGrowth)
planta
```
## ¿Qué podemos suponer según nuestros datos? {.smaller}
**1. ¿Qué tipos de pruebas podríamos aplicar?**
<br>
**2. ¿Por qué podemos aplicar dichas pruebas?**
<br>
**3. ¿Cuántos grupos tenemos?**
<br>
**4. ¿Qué concluímos en este punto?**

## Contexto de los datos {.smaller}
Tenemos 30 datos. Se comparan 3 grupos (un control) y dos tratamientos según la variación el peso.
<br>
**Planteamiento del problema**
<br>
Variable dependiente: Peso
<br>
Variable independiente: Grupo 
<br>
**Formulación de hipótesis**

## Formulación de hipótesis {.smaller}
```{r}
#| echo: false
valor_p<-c("p>0.05", "p<0.05")
hp<-c("Hipótesis nula (HO)", "Hipótesis alternativa (H1)")
formulacion<-c("No hay diferencias significativas en el peso de las plantas en los tratamientos","Hay diferencias significativas en el peso de las plantas en al menos uno de los tratamientos")
hipotesis<-data.frame(hp, formulacion, valor_p)
colnames(hipotesis)<-c("Hipótesis", "Formulación de la hipótesis", "Valor P")
hipo_kable<- kable(hipotesis)
hipo_kable
```
Este será nuestro planteamiento. Lo siguiente que podríamos hacer es hacer una evaluación visual sobre qué tenemos y cómo podemos partir para llegar a una respuesta. 

## Evaluación de supuestos {.smaller}

Primero hagamos un histograma.
```{r}
library(ggplot2)
ggplot(planta)+
  geom_histogram(aes(x=planta$weight, fill = group), position = "identity")

```
## Esta será otra forma más simple de verlo {.smaller}

```{r}
hist(planta$weight, col = "gold", xlab = "Pesos", ylab = "Frecuencias", main = "¿Qué podemos analizar aquí? ")

```

## Prueba de Shapiro-Wilk {.smaller}
La prueba de Shapiro-Wilk permite que evaluemos si existe o no normalidad en nuestros datos. 
```{r}
#| echo: false
valor_p1<-c("p>0.05", "p<0.05")
hp1<-c("Hipótesis nula (HO)", "Hipótesis alternativa (H1)")
formulacion1<-c("Nuestros datos se ajustan a la curva de normalidad","Nuestros datos NO se ajustan a la curva de normalidad")
hipotesis1<-data.frame(hp1, formulacion1, valor_p1)
colnames(hipotesis1)<-c("Hipótesis", "Formulación de la hipótesis", "Valor P")
hipo_kable1<- kable(hipotesis1, label = "Prueba de hipótesis para Shapiro-Wilk")
hipo_kable1


```
**Al proceder con la función podemos tener**
```{r}
#| echo: true
shapiro.test(planta$weight)

```
**Qué podemos concluir?**

## Homocedasticidad {.smaller}

La homocedasticidad en este caso se refiere a a la homogeneidad de varianzas. Existen 2 pruebas principales que pueden usarse para seguir con el análisis paramétrico o no paramétrico.
<br>
Debemos considerar Levene o Bartlet.
<br>
```{r}
#| echo: false
library(knitr)
valor_p2<-c("p>0.05", "p<0.05")
hp2<-c("Hipótesis nula (HO)", "Hipótesis alternativa (H1)")
formulacion2<-c("No hay diferencia significativa entre las varianzas","Hay diferencia significativa entre las varianzas")
hipotesis2<-data.frame(hp1, formulacion1, valor_p1)
colnames(hipotesis2)<-c("Hipótesis", "Formulación de la hipótesis", "Valor P")
hipo_kable2<- kable(hipotesis2, label = "Prueba de hipótesis para Homogeneidad de Varianzas")
hipo_kable2
```
**Posteriormente aplicamos las pruebas teniendo en cuenta ciertos criterios**
<br>
*Levene es más robusta ante diferencias de normalidad, o existan dudas. Se aplica en cualquier caso.*
*Bartlett es más robusta al detectar variaciones en la normalidad, pero es mejor cuando hay normalidad.*

# Según lo observado, ¿Qué podemos aplicar? {.smaller}


## Ejercicio práctico No. 2 {background-color="aquamarine"}
*Si hemos observado la normalidad, ¿Qué prueba y bajo que criterio debemos hacerlo?*

## Aplicación de la prueba {.smaller}
Entendiendo que nuestro valor fue 0.8915 por tanto sugiere *p>0.05*, entonces, aplicamos Bartlett. 
```{r}
#| echo: true
bartlett.test(planta$weight ~ planta$group) #Prueba de Bartlett
library(car)
leveneTest(planta$weight ~ planta$group)

```
**¿Qué podemos concluir?**

## Pruebas Paramétricas {.smaller}
Una prueba paramétrica se aplica cuando el criterio de normalidad se cumple tras los supuestos. 

```{r}
pruebas.parametricas<-c("T de Student", "ANOVA de una vía", "Correlación de Pearson", "Chi cuadrado de independencia")
pruebas.no.paramétricas<-c("Prueba de Wilcoxon - Mann Whitney U test", "Prueba de Kruskal-Wallis", "Correlación de Spearman","Prueba de Chi-Cuadrado ´Fisher exact test")
pruebas<-data.frame(pruebas.parametricas, pruebas.no.paramétricas)
colnames(pruebas)<-c("Pruebas Paramétricas", "Pruebas NO paramétricas")
kable_pruebas<-kable(pruebas)
kable_pruebas
```


## T de Student {.smaller}
Podemos aplicar la prueba así. 

```{r}
#| echo: true 
class(PlantGrowth)
grupo_planta.split <- split(PlantGrowth$weight, PlantGrowth$group)
t.test(grupo_planta.split$ctrl, grupo_planta.split$trt1)
```
**Nuestro valor p es 0.2504** o sea que *p>0.05*
<br>
**¿Qué podemos inferir?**

## Anova de una vía {.smaller}
La aplicación de ANOVA de una vía implica que tomamos en cuenta una de las colas, o sea hacemos alusión a una de las variables. 
```{r}
#| echo: true 
anova<-aov(PlantGrowth$weight ~ PlantGrowth$group)
summary(anova)
```
**¿Qué podemos inferir sobre nuestros resultados para la prueba paramétrica?** 


## Pruebas no Paramétricas {.smaller}
Una prueba **NO** paramétrica se aplica cuando el criterio de normalidad no se cumple tras los supuestos. 
<br>
Para propósitos del ejercicio aplicaremos usaremos el mismo dataset. 
```{r}
#| echo: true 
kruskal_wallis<- kruskal.test(PlantGrowth$weight ~ PlantGrowth$group)
kruskal_wallis
```
**¿Qué podemos inferir?**

## Sobre nuestros resultados obtenidos {.smaller}
**En caso de ser una prueba paramétrica. Tendríamos que:**

```{r}
#| echo: false
library(knitr)
valor_p3<-c("p>0.05", "p<0.05")
hp3<-c("Hipótesis nula (HO)", "Hipótesis alternativa (H1)")
formulacion3<-c("No hay diferencia significativa entre los grupos","Hay diferencia significativa entre los grupos")
hipotesis3<-data.frame(hp3, formulacion3, valor_p3)
colnames(hipotesis3)<-c("Hipótesis", "Formulación de la hipótesis", "Valor P")
hipo_kable3<- kable(hipotesis3, label = "Prueba de hipótesis para una prueba paramétrica")
hipo_kable3
```
**En caso de tener una prueba no paramétrica:**
```{r}
#| echo: false
library(knitr)
valor_p4<-c("p>0.05", "p<0.05")
hp4<-c("Hipótesis nula (HO)", "Hipótesis alternativa (H1)")
formulacion4<-c("No hay diferencia significativa entre los grupos","Hay diferencia significativa entre los grupos")
hipotesis4<-data.frame(hp4, formulacion4, valor_p4)
colnames(hipotesis4)<-c("Hipótesis", "Formulación de la hipótesis", "Valor P")
hipo_kable4<- kable(hipotesis4, label = "Prueba de hipótesis para una prueba NO paramétrica")
hipo_kable4
```
**Entonces, ¿Qué podemos suponer?**


## Pruebas *Pos-hoc* paramétricas {.smaller}
Se pueden utilizar cuando se quiere saber la diferencia entre grupos específicos entre sí. 
<br>
**¿Cuándo puede aplicarse?**
<br>
Pueden aplicarse cuando se cumpla los supuestos paramétricos. 
<br>
Podemos aplicar la prueba de Tukey que es una prueba paramétrica que combina todas las posibles combinaciones entre grupos para saber cuál es significativamente diferente. 
```{r}
#| echo: true
TukeyHSD(anova)

```

## Pruebas *Pos-hoc* no paramétricas {.smaller}

Un ejemplo podría ser (Aunque en este caso no es aplicable realmente), sería la prueba de Dunn,que compara pares de grupos con ajustes para múltiples comparaciones. Es la alternativa para Kruskal-Wallis. 
```{r}
#| echo: true
library(dunn.test)
dunn.test(PlantGrowth$weight, PlantGrowth$group, method = "bonferroni")

```


## ¿Qué podemos concluir? {.smaller}
En el caso que sí es adecuado: 
<br>
**Tras la solución de t de student no hay diferencias significativas entre ambos grupos**
<br>
**Tras la solución de ANOVA de una vía concluímos que hay mayor variabilidad entre los grupos y que hay diferencias significativas entre ellos**

# Muchas gracias {.smaller}







